{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "https://course.spacy.io/chapter2\n",
    "\n",
    "### continued from less02.py\n",
    "where I switched from python script to a notebook in Jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# \n",
    "from print_util import print_doc_analysis, print_matcher_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = English()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 |  is_alpha True | is_punct False | like_num False | is_title False | POS VERB | Text: testing\n",
      "Index: 1 |  is_alpha False | is_punct False | like_num True | is_title False | POS NUM | Text: 1\n",
      "Index: 2 |  is_alpha False | is_punct True | like_num False | is_title False | POS PUNCT | Text: ,\n",
      "Index: 3 |  is_alpha False | is_punct False | like_num True | is_title False | POS NUM | Text: 2\n",
      "Index: 4 |  is_alpha False | is_punct True | like_num False | is_title False | POS PUNCT | Text: ,\n",
      "Index: 5 |  is_alpha False | is_punct False | like_num True | is_title False | POS NUM | Text: 3\n",
      "Index: 6 |  is_alpha False | is_punct True | like_num False | is_title False | POS PUNCT | Text: ,\n",
      "Index: 7 |  is_alpha False | is_punct False | like_num True | is_title False | POS NUM | Text: 4\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"testing 1, 2, 3, 4\")\n",
    "print_doc_analysis(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Efficient Phrase Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"countries.json\") as f:\n",
    "        COUNTRIES = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipe a list\n",
    "COUNTRIES is a list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTRIES type: <class 'list'>\n",
      "nlp.pipe type: <class 'generator'>\n",
      "patterns type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('COUNTRIES type:', type(COUNTRIES))\n",
    "\n",
    "countries_pipe = nlp.pipe(COUNTRIES)\n",
    "print('nlp.pipe type:', type(countries_pipe))\n",
    "\n",
    "patterns = list(countries_pipe)\n",
    "print('patterns type:', type(patterns))\n",
    "\n",
    "matcher.add(\"COUNTRY\", None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 : Czech Republic\n",
      "4 5 : Slovakia\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "print_matcher_results(doc,matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## 15 Extract Countries & Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document length: <class 'str'> 4577\n"
     ]
    }
   ],
   "source": [
    "with open(\"country_text.txt\") as f:\n",
    "    TEXT = f.read()\n",
    "    \n",
    "print (\"document length:\", type(TEXT), len(TEXT))\n",
    "# print ('TEXT:', TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()   # note - learned this the hardway - you need to re-initialize nlp - not sure why\n",
    "                  #      - you might have a problem where you didn't clear nlp.pipe?\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "patterns = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add(\"COUNTRY\", None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial doc.ents: <class 'tuple'> ()\n",
      " - - - - -  - - - -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(TEXT)\n",
    "print ('initial doc.ents:', type(doc.ents), doc.ents)\n",
    "print (' - - - - -  - - - -')\n",
    "# print_doc_analysis(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iterate over the matches - create a span with label GPE (geoplitical entity)\n",
    "2. Overwrite the entities in doc.ents and add the matched span\n",
    "3. get the matched span root head token\n",
    "4. print head and span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Namibia  :  Namibia --> Namibia\n",
      "2 South Africa  :  South --> South Africa\n",
      "3 Cambodia  :  Cambodia --> Cambodia\n",
      "4 Kuwait  :  Kuwait --> Kuwait\n",
      "5 Somalia  :  Somalia --> Somalia\n",
      "6 Haiti  :  Haiti --> Haiti\n",
      "7 Mozambique  :  Mozambique --> Mozambique\n",
      "8 Somalia  :  Somalia --> Somalia\n",
      "9 Rwanda  :  Rwanda --> Rwanda\n",
      "10 Singapore  :  Singapore --> Singapore\n",
      "11 Sierra Leone  :  Sierra --> Sierra Leone\n",
      "12 Afghanistan  :  Afghanistan --> Afghanistan\n",
      "13 Iraq  :  Iraq --> Iraq\n",
      "14 Sudan  :  Sudan --> Sudan\n",
      "15 Congo  :  Congo --> Congo\n",
      "16 Haiti  :  Haiti --> Haiti\n"
     ]
    }
   ],
   "source": [
    "# doc.ents = () -- that it nothing, given your reintialized nlp\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # 1 - create the span\n",
    "    span = Span(doc, start, end, label=\"GPE\")\n",
    "    # 2 - overwrite entities\n",
    "    doc.ents = list(doc.ents) + [span]\n",
    "    \n",
    "    # 3 - get the root head token\n",
    "    span_root_head = span.root.head\n",
    "    # 4 - print\n",
    "    doc_ents_length = len(list(doc.ents))\n",
    "    print(doc_ents_length, span, ' : ', span_root_head.text, \"-->\", span.text)\n",
    "    # print (doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "[('Namibia', 'GPE'), ('South Africa', 'GPE'), ('Cambodia', 'GPE'), ('Kuwait', 'GPE'), ('Somalia', 'GPE'), ('Haiti', 'GPE'), ('Mozambique', 'GPE'), ('Somalia', 'GPE'), ('Rwanda', 'GPE'), ('Singapore', 'GPE'), ('Sierra Leone', 'GPE'), ('Afghanistan', 'GPE'), ('Iraq', 'GPE'), ('Sudan', 'GPE'), ('Congo', 'GPE'), ('Haiti', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "# Print the entities in the document\n",
    "print (type(doc.ents))\n",
    "print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"GPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
